{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import *\n",
    "from os import listdir\n",
    "from os.path import join,basename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAvg(x,kernel,boundaryCondition='periodical'):\n",
    "    \"\"\"\n",
    "    Return the local average matrix\n",
    "    \"\"\"\n",
    "    if boundaryCondition == 'periodical':\n",
    "        nrow,ncol = x.shape[0],x.shape[1]\n",
    "        x1 = np.zeros((nrow+2,ncol+2))\n",
    "        x1[1:-1,1:-1] = x\n",
    "        x1[0,1:-1] = x[-1,:]\n",
    "        x1[-1,1:-1] = x[0,:]\n",
    "        x1[1:-1,0] = x[:,-1]\n",
    "        x1[1:-1,-1] = x[:,0]\n",
    "\n",
    "        x1[0,0] = x1[0,-2]\n",
    "        x1[0,-1] = x1[0,1]\n",
    "        x1[-1,-1] = x1[-1,1]\n",
    "        x1[-1,0] = x1[-1,-2]\n",
    "    \n",
    "    else:\n",
    "        x1 = np.zeros((nrow+2,ncol+2))\n",
    "        x1[1:-1,1:-1] = x\n",
    "        x1[0,1:-1] = x[0,:]\n",
    "        x1[-1,1:-1] = x[-1,:]\n",
    "        x1[1:-1,0] = x[:,0]\n",
    "        x1[1:-1,-1] = x[:,-1]\n",
    "\n",
    "        x1[0,0] = x1[0,1]\n",
    "        x1[0,-1] = x1[0,-2]\n",
    "        x1[-1,-1] = x1[-1,-2]\n",
    "        x1[-1,0] = x1[-1,1]\n",
    "    \n",
    "    xAvg = scipy.signal.convolve2d(x1,kernel,mode='same')\n",
    "    xAvg = xAvg[1:-1,1:-1]\n",
    "    return xAvg\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeCurl(uv):\n",
    "    u = uv[:,:,0]\n",
    "    v = uv[:,:,1]\n",
    "\n",
    "    # simple kernel\n",
    "    nrows,ncols = u.shape[0], u.shape[1]\n",
    "    # add boundary\n",
    "    u1 = np.zeros((nrows+2,ncols))\n",
    "    u1[0,:] = u[0,:]\n",
    "    u1[-1,:] = u[-1,:]\n",
    "    u1_copy = np.zeros((nrows+2,ncols+2))\n",
    "    u1_copy[:,1:-1] = u1\n",
    "    u1_copy[:,0] = u1[:,1]\n",
    "    u1_copy[:,-1] = u1[:,-1]\n",
    "    # add boundary\n",
    "    v1 = np.zeros((nrows+2,ncols))\n",
    "    v1[0,:] = v[0,:]\n",
    "    v1[-1,:] = v[-1,:]\n",
    "    v1_copy = np.zeros((nrows+2,ncols+2))\n",
    "    v1_copy[:,1:-1] = v1\n",
    "    v1_copy[:,0] = v1[:,1]\n",
    "    v1_copy[:,-1] = v1[:,-1]\n",
    "\n",
    "    kernel = np.array([[-1,0,1],[-2,0,2],[-1,0,1]])*1/8 #used to detect vertical lines\n",
    "    uy = scipy.signal.convolve2d(u,kernel.T,mode='same') #detect horizontal lines for x velocity\n",
    "    vx = scipy.signal.convolve2d(v,kernel,mode='same') #detect vertical lines for y velocity\n",
    "    uy = uy[1:-1,1:-1]\n",
    "    vx = vx[1:-1,1:-1]\n",
    "    vort = vx - uy\n",
    "\n",
    "    # complex kernel\n",
    "    h = np.array([-1, 9, -45, 0, 45, -9, 1])/60;        # derivative used by Bruhn et al \"combing \"IJCV05' page218\n",
    "    vx = scipy.ndimage.correlate(v, h, mode='nearest').transpose() #MATLAB returns transpose of the expected answer\n",
    "    uy = scipy.ndimage.correlate(u, h.T, mode='nearest').transpose()\n",
    "    vort = vx - uy\n",
    "    return vort\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HS_estimation(im1,im2,uLast,vLast,lamb=1,iter=200,boundaryCondition='periodical',estimation_method='HS'):\n",
    "    \"\"\"\n",
    "    Adapted from Shengze Cai\n",
    "    https://github.com/shengzesnail/coarse_to_fine_HS_PIV/blob/master/HS_Estimation.m\n",
    "    im1,im2 (np.array): two subsequent frames or images.\n",
    "    lamb (float): lambda, a parameter that reflects the influence of the smoothness term.\n",
    "    iter (int): number of iterations.\n",
    "    uLast, vLast (float): the flow field estimates of last pyramid; default is zero.\n",
    "    estimationMethod (str): either HS or TE (where transport equation is considered in the constraint)\n",
    "    \"\"\"\n",
    "    uInitial = uLast\n",
    "    vInitial = vLast\n",
    "    u = uInitial\n",
    "    v = vInitial\n",
    "\n",
    "    # Estimate Spatiotemporal derivatives of images\n",
    "    fx, fy, ft, fxy = computeDerivatives_f(im1, im2, boundaryCondition)\n",
    "\n",
    "    # averaging kernel\n",
    "    kernel_1=[[0, 1/4, 0],[1/4, 0 ,1/4],[0, 1/4, 0]]\n",
    "\n",
    "    for i in range(iter):\n",
    "        # Compute local averages of the flow vectors\n",
    "        uAvg = computeAvg(u,kernel_1,boundaryCondition)\n",
    "        vAvg = computeAvg(v,kernel_1,boundaryCondition)\n",
    "        if estimation_method == 'HS':\n",
    "            Diffu = 0\n",
    "        else:\n",
    "            Diffu = -(1/Re/Sc)*fxy\n",
    "        \n",
    "        #Compute flow vectors constrained by its local average and the optical flow constraints\n",
    "        data = ( fx * (uAvg-uLast) ) + ( fy * (vAvg-vLast) ) + ft + Diffu\n",
    "        u = uAvg - ( fx * ( data ) ) / ( lamb + fx**2 + fy**2)\n",
    "        v = vAvg - ( fy * ( data ) )/ ( lamb + fx**2 + fy**2)\n",
    "    \n",
    "    return u,v\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HS_pyramids(im1,im2,lamb,PARA,uvInitial):\n",
    "    \"\"\"\n",
    "    Horn-Schunck Motion Estimation Using Multi-Pyramids (Multi-Resolution)\n",
    "    Ref:\t\n",
    "    Ruhnau, P., et al. (2005) Experiments in Fluids 38(1):21-32.\n",
    "    Heitz, D., et al. (2010) Experiments in Fluids, 48(3):369-393.\n",
    "    Sun, D., et al. (2010). Computer Vision & Pattern Recognition.\n",
    "\n",
    "    Usage: [u, v] = HS_Pyramids(img1,img2,lambda,PARA)\n",
    "    ********** inputs ***********\n",
    "    im1,im2 (np.array): two subsequent frames or images (greyscale).\n",
    "    lambda (float): a parameter that reflects the influence of the smoothness term.\n",
    "    PARA: parameters\n",
    "    ********** outputs ************\n",
    "    u, v: the velocity components\n",
    "\n",
    "    Shengze Cai, 2016/03\n",
    "    \"\"\"\n",
    "    # initialise the velocity field\n",
    "    if uvInitial is None:\n",
    "        uInitial = np.zeros(im1.shape)\n",
    "        vInitial = np.zeros(im1.shape)\n",
    "        uvInitial = np.stack([uInitial,vInitial],axis=2)\n",
    "\n",
    "    \n",
    "\n",
    "    def Estimate(im1,im2,lamb,uvInitial,PARA):\n",
    "        # Run Horn_schunck on all levels and interpolate\n",
    "        warp_iter = PARA.warp_iter\n",
    "        sizeOfMF = PARA.sizeOfMF\n",
    "        isMedianFilter = PARA.isMedianFilter\n",
    "        Dx = uvInitial[:,:,0] #delta x\n",
    "        Dy = uvInitial[:,:,1] #de;ta y\n",
    "\n",
    "        #consruct image pyramid for gnc stage 1\n",
    "        pyramid_level = PARA.pyramid_level\n",
    "        G1 = image_pyramid(im1,pyramid_level)\n",
    "        G2 = image_pyramid(im2,pyramid_level)\n",
    "        # iteration\n",
    "        level = pyramid_level\n",
    "        for l in range(level+1):\n",
    "            small_im1 = G1[l]\n",
    "            small_im2 = G2[l]\n",
    "            sz = small_im1.shape\n",
    "            uv = resample_flow(np.stack([Dx,Dy],2),sz)\n",
    "            Dx = uv[:,:,0]\n",
    "            Dy = uv[:,:,1]\n",
    "\n",
    "            for iwarp in range(warp_iter):\n",
    "                W1 = warp_forward(small_im1,Dx,Dy,PARA.interpolation_method)\n",
    "                W2 = warp_inverse(small_im2, Dx,Dy,PARA.interpolation_method)\n",
    "                Dx,Dy = HS_estimation(W1,W2,lamb, PARA.iter,Dx,Dy,PARA.boundaryCondition)\n",
    "\n",
    "                if (isMedianFilter is True):\n",
    "                    Dx = scipy.ndimage.median_filter(Dx,sizeOfMF)\n",
    "                    Dy = scipy.ndimage.median_filter(Dy,sizeOfMF)\n",
    "\n",
    "        return Dx, Dy\n",
    "    \n",
    "    # Run HS with multi-pyramids\n",
    "    u, v = Estimate(im1, im2, lamb, uvInitial,PARA)\n",
    "\n",
    "    return u,v\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PARA:\n",
    "    \"\"\"\n",
    "    parameters settings\n",
    "    \"\"\"\n",
    "    def __init__(self,pyramid_level,warp_iter,iter,boundaryCondition='periodical',interpolation_method='spline',isMedianFilter=True,sizeOfMF=(5,5)):\n",
    "        self.pyramid_level = pyramid_level\n",
    "        self.warp_iter = warp_iter\n",
    "        self.iter = iter\n",
    "        #Boundary conditions\n",
    "        self.boundaryCondition = boundaryCondition\n",
    "        self.interpolation_method = interpolation_method\n",
    "        #Divergence_free decomposition and the settings\n",
    "        self.isMedianFilter = isMedianFilter\n",
    "        self.sizeOfMF = sizeOfMF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11 ('image_processing')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "824ccbd0db9d92c4aa655aed039d0a81ef5cb790b435ea04aa20391982a69284"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
